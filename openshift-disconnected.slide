OpenShift in a Disconnected world
21 Sep 2021
Tags: OpenShift, Disconnected, IPv6

Juan Manuel Parrilla
Principal Software Engineer, Red Hat
jparrill@redhat.com

Mario Vazquez Cebrian
Principal Software Engineer, Red Hat
mavazque@redhat.com

* The disconnected environments are dark places!

.image assets/img/zelda.jpg 400 600

Be sure you check the documentation before to start dealing with a real one!
.background assets/img/background.png

########

* Index

- Pre-requisites

    - The Helper node
    - Kernel Parameters
    - Additional Services: DHCP, DNS, etc...
    - Container Image Sync
    - Download RHCOS Resources
    - Networking
    - The install-config file
    - CatalogSources and ICSPs

- OCP Deployment
    
    - UPI/IPI
    - Deployment Customization

- OpenShift and Operators Life-cycle

.background assets/img/background.png

########
* Pre-requisites

.background assets/img/background.png

########
* Pre-requisites: Helper Node

Basically all pre-requisites comes from the *helper* *node*. We call a helper node to that one which gives the basic services to that environment, like DNS, DHCP, HTTPD, etc... So let's create a list of services necessary to make this work:

.image assets/img/pre-reqs.png 370 780

.background assets/img/background.png

########
* Pre-requisites: Helper Node
We can classify them as you see in the diagram:

- Mandatory
- Mandatory for Disconnected
- Mandatory for IPv6
- Optional Components

.background assets/img/background.png

########
* Pre-requisites: Helper Node

- As *DNS* and *DHCP* we will use `Dnsmasq` software because it can hold both configs.
- For *NTP* we will use `Chrony`
- For *Internal* *Registry* we will use a podman container with a basic image registry
- For the *HTTP* server we will use `HTTPD`
- For RA's and route spreading on the IPv6 environment we will use RaDVD
- To allow access to the OpenShift Console and the BMC's we will have an *HAProxy* that makes the IPv4>IPv6 translation

These are the basic components on the Helper Node.

.background assets/img/background.png

########
* Pre-requisites: Kernel Parameters

Another important things to make sure the services on the Helper Node works fine, we need to add these config to the Kernel:

    # Enable IPv6 Forwading for all interfaces
    net.ipv6.conf.all.forwarding=1
    
    # Accept RA's even if forwarding is enabled
    net.ipv6.conf.all.accept_ra=2
    
    # Reverse Path not validated
    net.ipv4.conf.all.rp_filter=0
    
    # Disable IPv6 Loopback config
    net.ipv6.conf.lo.disable_ipv6=0

.link https://sysctl-explorer.net

.background assets/img/background.png
########
* Pre-requisites: Additional Services
Firstly we need a couple of mandatory services, they will be DNS and NTP.

- DNS needs to at least resolve the main openshift addresses, which are the Ingress, the API and the api-int, also the OCP master nodes and lastly our helper node. (This last one for the Image Registry.
- The NTP is also mandatory in a multinode deployment, we usually put a server on the Helper node and allow the network we are on the `chrony.conf`
- The Pull Secret is to get the proper access to the images for the installation and Image Synchronization process
.background assets/img/background.png

########
* Pre-requisites: Image Sync

To start the image synchronization for the OCP installation it's quite easy, we will just need to :

- Create a TLS Certificate for our registry with the proper DNS name (it should be SSL)
.code assets/src/cert-maker.sh /^host/,/htpasswd/
.background assets/img/background.png

########
* Pre-requisites: Image Sync
- Start the Image Registry in local
.code assets/src/start-registry.sh /^podman/,/docker/

> Apart from the desired configuration for your registry ensure the compatibility `schema1` it's enabled
.background assets/img/background.png

########
* Pre-requisites: Image Sync

- Download the official oc client and fill the script vairables 
.code assets/src/release-sync-full.sh /^# Variables/,/NO/

- Now execute the synchronization:
.code assets/src/release-sync-full.sh /^*oc adm/,/--to-release-image/

.background assets/img/background.png

########
* Pre-requisites: Download RHCOS Resources

Once synced the container images, we need to download the RHCOS images for the OCP deployment, to do that we have a script to help you that extracts the information from the OpenShift installer:

- Download the OpenShift-Baremetal Installer

.code assets/src/release-sync-full.sh /^*Downloading IPI/,/--to ./
This will extract the IPI installer binary from the desired release you wanna install.
Ensure you move to the OS path and change the execution permissions flag on the binary.
.background assets/img/background.png

########
* Pre-requisites: Download RHCOS Resources
- Download the RHCOS Images

For that we use the Installer to extract the proper URLs for the selected release (which are hardcoded), this is a sample about how to extract them but you can find all needed resources in the `assets/src/release-sync-full.sh` script 

    # RHCOS Version
    openshift-baremetal-install coreos print-stream-json \
    | jq -r '.["architectures"]["x86_64"]["artifacts"]["metal"]["release"]'

    # RHCOS ISO URI
    openshift-baremetal-install coreos print-stream-json \
    | jq -r '.["architectures"]["x86_64"]["artifacts"]["metal"]["formats"]["iso"]["disk"]["location"]'

These ones and some more are necessary to install our OCP Hub Cluster, the script will help you to identify which ones are necessary and where to place them.

.background assets/img/background.png
########

* Pre-requisites: Download RHCOS Resources

Summarizing you will need these elements to place them into the `install-config.yaml` file:

- QEMU URI
- QEMU SHA256 Uncompressed
- OPENSTACK URI
- OPENSTACK SHA256 Compressed

In the `install-config.yaml` format will be something like:

    bootstrapOSImage: http://[2100:52:1302::1]/rhcos-qemu.x86_64.qcow2.gz?sha256=17868a1963ae2eae25...
    clusterOSImage: http://[2100:52:1302::1]/rhcos-openstack.x86_64.qcow2.gz?sha256=6ab5c6413f27527...

The IPv6 with the image name is our internal server hosting the images
The `sha256=...` is the hash referenced on the binary

.background assets/img/background.png

########
* Pre-requisites: Networking 

The networking part I think it's a bit tricky, because you need to know how IPv6 works in a generic network with the RA/NA/ND and so on, once you know that, you need apply it to your network checking with your network admin if some capabilities are disabled or not, let's get into it.

Important points to discuss:

- DNSMASQ and RAs
- IPv6 and SLAAC Addresses
- PXE vs VirtualMedia
- BootMode: UEFI vs Legacy


.background assets/img/background.png
########

* DNSMASQ and RAs 

- Configure your network to send the RAs from RaDVD instead use the dnsmasq native one
- `AdvOnLink` `on` and `AdvRouterAddr` `on` are mandatory options if not, NM will get confused
- use *ndptool* to to debug the RAs sent over the network

    ndptool mon -i 'baremetal.154' -t ra

.background assets/img/background.png
########

* IPv6 and SLAAC Addresses 

- SLAAC addresses are the devil if you are not the network admin 
- Check if it's enabled or not with `ndptool`
.image assets/img/slaac_trace.png 200 950
- The issue here is, network devices will be always faster than a server so slaac will be configured first
- The routes and the dns resolution will be affected.

.background assets/img/background.png
########

* PXE vs VirtualMedia 

- PXE will involve a more complex net config and usually are not allowed in all companies
- This method involve L2 on the provisioning network
- Virtualmedia is the most easy way always that your BMC servers has redfish configured (we recommend Dell or HP)
- This method only will need L3 and does not need provisinoning network.

.background assets/img/background.png
########

* UEFI vs Legacy 

- This mainly affects to the drives on the node where OCP will be deployed
- If they are NVMe you need UEFI
- In other case you can choose Legacy but also works with UEFI
- UEFI boot should has secure boot disabled

.background assets/img/background.png
########

* The Install Config file

.background assets/img/background.png
########

* The Install Config file

If you are deploying OpenShift this is one of the main pieces let's check the relevant fields inside
.code assets/src/install-config.yaml /^networking/,/baremetal/

.background assets/img/background.png
########

* The Install Config file

.code assets/src/install-config.yaml /^platform/,/hardwareProfile/

.background assets/img/background.png
########

* The Install Config file

.code assets/src/install-config.yaml /^imageContentSources:/,/source/
.code assets/src/install-config.yaml /^additionalTrustBundle:/,/  BQAwgYg/
.code assets/src/install-config.yaml /^pullSecret/,/ssh-rsa/

.background assets/img/background.png
########

* CatalogSources and ICSPs

.background assets/img/background.png
########

* CatalogSources

A CatalogSource is a K8s object that allow the OLM (Operator Lifecycle Manager) to consume PackageManifests included on that source.

- Namespaced resources that live on the openshift-marketplace Namespace
.image assets/img/catalogsource.png 80 1000
.code assets/src/catalogsource.yaml /name/,/interval/

.background assets/img/background.png
########

* CatalogSources

The CatalogSource points to an index image which contains a serie of objects that K8s parse as `PackageManifests`

- One CatalogSouce could contain 1 or N packagemanifest
- You can decide how many include in every CS
- OCP has 4 included by default pointing to Red Hat registry
- You can disable them in case of disconnected deployments
- The index image contains a DB whith the data for every PackageManifests included

.image assets/img/packagemanifest.png

.background assets/img/background.png
########

* CatalogSources

- If you wanna inspect the content of an index, just run it on podman as you see
.image assets/img/cs-serve.png 50 950

- Then in other terminal use `gprcurl` to check the content:
.image assets/img/cs-packages.png

You can use `opm` and tool to create you own indexImages and then push it to your internal registry to be consumed for your own CatalogSources.

.background assets/img/background.png
########

* CatalogSources

- Create the Index Image in local
    opm index prune --from-index registry.redhat.io/redhat/redhat-operator-index:v4.8 \
        --packages advanced-cluster-management,local-storage-operator... \
        --tag bm-cluster-1-hyper.e2e.bos.redhat.com:5000/olm-index/redhat-operator-index:v4.8
    
- Push Index image to your internal Registry
    podman push --tls-verify=false --authfile pull_secret.json \
        bm-cluster-1-hyper.e2e.bos.redhat.com:5000/olm-index/redhat-operator-index:v4.8 

- Sync the images listed on your Image from the source registry (RedHat) to your internal Registry
    oc adm catalog mirror --registry-config=pull_secret.json \ 
        bm-cluster-1-hyper.e2e.bos.redhat.com:5000/olm-index/redhat-operator-index:v4.8 \
        bm-cluster-1-hyper.e2e.bos.redhat.com:5000/olm 

.background assets/img/background.png
########

* The ICSPs

Stands for ImageContentSourcePolicy and the concept behind this object it's easy to understand

- It works at runtime level
- When crio/podman go to pull an image, it will look at the `/etc/containers/registries.conf` file
- If the requested image matches with and entry on that file it will go to the mirror in first step

ICSP it's a K8s object that create these entries on the OCP nodes.

The controller that manage this object is the MachineConfig Operator, so make sure you don't have it in degraded state

    oc get mcp

.background assets/img/background.png
########

* The ICSPs

This is how looks like an ICSP
.code assets/src/icsp.yaml /apiVersion/,/source/

And the result on the `/etc/containers/registries.conf` file
.code assets/src/registries.conf /registry/,/bm-cluster-1-hyper.e2e.bos.redhat.com:5000/

.background assets/img/background.png
########

* The ICSPs

But Warning, you need to know these things:

- If you have the MCO degraded ICSP will not be applied
- If you modify the OCP Nodes manually at this `registries.conf` file the MCO will enter on degraded state
- If you decide that you want to modify the node manually, you need to restart kubelet and crio after modify this file to make this work
- The flag `mirror-by-digest-only` `=` `true` will be exposed on the API on 4.9 and you will be able the modify this directly on the ICSP 
- You should not include tags on the ICSP
- You can save some lines puting the namespace instead the whole image


.background assets/img/background.png
########

* OpenShift Deployment


.background assets/img/background.png
########

* OpenShift Deployment

There are 2 native types of deployments of OpenShift, but both of them have minimum requirements that requires user interaction with the environment:

- Create the proper DNS and DHCP entries
- Helper node configuration like networking, kernel parameters, etc...
- Client and Installer extracted from the OCP Release
- Images download (Qemu and Openstack ones)
- Prepare BareMetalHost (BMC config if the deployment will be on BM)

From this point we can talk about the specific needs


.background assets/img/background.png
########

* UPI: User Provided Infrastructure

The most flexible way and also the most difficult one. it has some caveats like, you will not be able to automatically create more workers in the cluster, you need to do it manually.

Where the user is responsible of:

- ISO Creation to boot the Bootstrap VM, this method needs to embed the necessary files on the ISO.
- ISO Creation to boot the VMs or the Baremetal Nodes, you have another option to use, which is based on PXE.
- Bootstrap VM creation (This VM will bootstrap the deployment creating some basic services like ETCD, CoreDNS, LB...)
- VM Creation (If the deployment of on top of the VMs) at some point when the bootstrap VM have the things prepared you will need to boot the nodes with a VirtualCD and those will try to configure themselves until they will reach the Bootstrap VM and form a ETCD Cluster.

.background assets/img/background.png
########

* UPI: User Provided Infrastructure

- The nodes form a ETCD cluster with the Bootstrap VM and then they will continue the deployment process of OpenShift.
- When you see a logtrace on the Bootstrap VM that says something like "Bootstrap process finished", you can delete the VM.
- The 3 nodes should be smart enough to finish the deployment by themselves.
- After that you can use the Kubeconfig to access to your cluster.

Here you can find many more detail about how to proceed

.link https://cloud.redhat.com/blog/ask-an-openshift-admin-office-hour-installation-methods-redux Installation Methods Redux

.background assets/img/background.png
########

* IPI: Installer Provided Infrastructure

Here you will need to download the Installer and the OC client, the best way to do this, is extracting it from the release as we showed before.

This method is one of the easiest ways to deploy OpenShift.

- You need to provide a Libvirtd URL to allow the Installer to create the Bootstrap VM
- You need to provide the provider and the credentials on the `install-config.yaml` file, like vsphere, RHEV, Openstack or even Baremetal
- If the deployment is disconnected you need to add some extra manifests to the deployment folder, the installer will take care to insert them on the multiple ISOs and that will be reflected on the Ignition files that the ISOs has inside.

.background assets/img/background.png
########

* IPI: Installer Provided Infrastructure

To deploy IPI is easy as you just execute a small script as this one:

.code assets/src/deploy.sh

- Depend on how did you mirrored the images, you will need the first export or not.
- We copy the install-config file inside the folder we create because during the initial part of the deployment, that one is consumed and it disspaear.
- We generate the manifests first, because this allow us to add some manifests like ICSPs or maybe MachineConfig that does something on deployment time.

.background assets/img/background.png
########

* IPI: Installer Provided Infrastructure

- After that we start the deployment using the last command on debug mode to follow every step.
- At some point the Bootstrap will be created and that one will boot the Nodes VMs/Baremetal it will depend on which provider did you select.
- The bootstrap VM will be deleted automatically by the Installer when this is not needed anymore.
- You will notice when the deployment finishes because a prompt will be shown on the shell, showing the user/password or the location of the Kubeconfig file to be accesible via Web or CLI.
- If the installer fails because of a timeout no worries, you can still wait a bit more using this command:
    
    openshift-baremetal-install --dir $CLUSTER --log-level debug wait-for install-complete

.background assets/img/background.png
########

* Alternative Methods

There are some alternative methods to have a Cluster, you can use the web UI on the SaaS located on cloud.redhat.com which provide a couple of more methods, but the most easy one is using the Infrastructure Operator that gives you a quick form to fill and then you just need to download an ISO to put into the master nodes and boot them all this installer will be smart enough to finish the deployment by himself.

You have a blogpost from one of our team members: 

.link https://cloud.redhat.com/blog/using-the-openshift-assisted-installer-service-to-deploy-an-openshift-cluster-on-metal-and-vsphere OCP Cluster on vsphere using Assisted Installer

The method using the SaaS also includes the capability to deploy an *SNO* *(Single* *Node* *OpenShift)* which the native install methods are not capable yet to deploy (But they will support that in the near future, so stay tunned!)

And the last one for brave people (and for sure this is not supported by Red Hat) you can use Kcli, more info here:

.link https://kcli.readthedocs.io/en/latest/#deploying-kubernetes-openshift-clusters-and-applications-on-top Deploy OpenShift 4 using Kcli

.background assets/img/background.png
########

* Questions?

.background assets/img/background.png
########

* Thank you 

.background assets/img/background.png
########
